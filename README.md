This project compares different sampling techniques when used upon various ML models for classification: following sampling techniques were used:

1.Random Sampling
2.Structured Sampling
3.Stratified sampling
4.cluster sampling
5.Weighted sampling

for the following ML models

1.logistic regression
2.Random forest classifier
3.Naive bayes
4.SVM
5.Decision Tree classifier
You can just run the file Main.py with the given dataset to find out which sampling is best for the following models 
PS: Oversampling using SMOTE was applied prior to applying these techniques.
Results
The results of the project showed that the best sampling technique for a particular machine 
learning model depends on the characteristics of the data set. For example, random sampling 
was found to be the best sampling technique for the logistic regression model, while 
stratified sampling was found to be the best sampling technique for the random forest 
classifier.
In general, it was found that stratified sampling and cluster sampling were the most effective 
sampling techniques for the machine learning models in the project. This is because these 
techniques ensure that the sample is representative of the population, which can improve the 
accuracy of the machine learning models.
